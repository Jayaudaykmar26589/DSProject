{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from audio_dataset import *\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio_dataset.py\n",
    "import librosa\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "audio_endings = ('.mp3', '.wav', '.flac')\n",
    "\n",
    "class AudioDataSet:\n",
    "    \"\"\"AudioDataset helps organize and load a audio dataset split into different directories. \n",
    "    Because audio takes up so much space, this will only load the clips that need to be used\"\"\"\n",
    "    def __init__(self, ds_dir, sr, duration, shuffle=True, random_state=42):\n",
    "        \"\"\"Initalize with the directory of audio files ds_dir (will scan all subdirectories recursively), \n",
    "        the sample_rate sr you wish to have on the whole dataset, and duration of the clips in seconds.\"\"\"\n",
    "        self.sr = sr\n",
    "        self.duration = duration\n",
    "\n",
    "        self.current_file_idx = 0\n",
    "        \n",
    "        self.files = []\n",
    "        for r, d, f in os.walk(ds_dir):\n",
    "            for file in f:\n",
    "                if file.endswith(audio_endings):\n",
    "                    self.files.append(os.path.join(r, file))\n",
    "                    \n",
    "        if shuffle:\n",
    "            rand = random.Random(random_state)\n",
    "            rand.shuffle(self.files)\n",
    "    \n",
    "    def num_samples(self):\n",
    "        \"\"\"The number of files/sampels in audio set.\"\"\"\n",
    "        return len(self.files)\n",
    "    \n",
    "    def load(self, file_idxs, sr=None, duration=None, pbar=None):\n",
    "        \"\"\"Load the specified file indices as an np array of shape (len(file_idxs), sr*duration)\"\"\"\n",
    "        if sr is None:\n",
    "            sr = self.sr\n",
    "        if duration is None:\n",
    "            duration = self.duration\n",
    "        ys = []\n",
    "        if pbar is not None:\n",
    "            pbar.reset(total=len(file_idxs))\n",
    "        for file_idx in file_idxs:\n",
    "            y, _ = librosa.load(self.files[file_idx], sr=sr, mono=True, offset=0.0, duration=duration)\n",
    "            y = librosa.util.fix_length(y, int(sr*duration), mode='wrap')\n",
    "            ys.append(y)\n",
    "            if pbar is not None:\n",
    "                pbar.update(1)\n",
    "        return np.array(ys)\n",
    "\n",
    "    def load_next(self, batch_size, sr=None, duration=None, pbar=None):\n",
    "        \"\"\"Load the next batch_size files as an np array of shape (batch_size, sr*duration)\"\"\"\n",
    "        if self.current_file_idx + batch_size > self.num_samples():\n",
    "            self.current_file_idx = 0\n",
    "            \n",
    "        file_idxs = range(self.current_file_idx, self.current_file_idx + batch_size)\n",
    "        self.current_file_idx += batch_size\n",
    "        return self.load(file_idxs, sr=sr, duration=duration, pbar=pbar)\n",
    "    def reset_next(self):\n",
    "        \"\"\"Reset the file index for the load_next function.\"\"\"\n",
    "        self.current_file_idx = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reformatting datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = 8000\n",
    "duration = 5.0\n",
    "voice_ds = AudioDataSet('datasets/LibriSpeech/LibriSpeech/dev-clean', sr=sr, duration=duration)\n",
    "noise_ds = AudioDataSet('datasets/urban/UrbanSound8K/audio', sr=sr, duration=duration)\n",
    "\n",
    "num_samples = voice_ds.num_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voice = voice_ds.load(range(num_samples), pbar=tqdm())\n",
    "print(voice.shape)\n",
    "np.save('datasets/voices', voice)\n",
    "del voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = noise_ds.load(range(num_samples), pbar=tqdm())\n",
    "print(noise.shape)\n",
    "np.save('datasets/noises', noise)\n",
    "del noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Fast Load Speeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "voice = np.load('datasets/voices.npy')\n",
    "noise = np.load('datasets/noises.npy')\n",
    "print(voice.shape)\n",
    "print(noise.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
