{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from audio_dataset import *\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio_dataset.py\n",
    "import librosa\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "audio_endings = ('.mp3', '.wav', '.flac')\n",
    "\n",
    "class AudioDataSet:\n",
    "    \"\"\"AudioDataset helps organize and load a audio dataset split into different directories. \n",
    "    Because audio takes up so much space, this will only load the clips that need to be used\"\"\"\n",
    "    def __init__(self, ds_dir, sr, duration, shuffle=True, random_state=42):\n",
    "        \"\"\"Initalize with the directory of audio files ds_dir (will scan all subdirectories recursively), \n",
    "        the sample_rate sr you wish to have on the whole dataset, and duration of the clips in seconds.\"\"\"\n",
    "        self.sr = sr\n",
    "        self.duration = duration\n",
    "\n",
    "        self.current_file_idx = 0\n",
    "        \n",
    "        self.files = []\n",
    "        for r, d, f in os.walk(ds_dir):\n",
    "            for file in f:\n",
    "                if file.endswith(audio_endings):\n",
    "                    self.files.append(os.path.join(r, file))\n",
    "                    \n",
    "        if shuffle:\n",
    "            rand = random.Random(random_state)\n",
    "            rand.shuffle(self.files)\n",
    "    \n",
    "    def num_samples(self):\n",
    "        \"\"\"The number of files/sampels in audio set.\"\"\"\n",
    "        return len(self.files)\n",
    "    \n",
    "    def load(self, file_idxs, sr=None, duration=None, pbar=None):\n",
    "        \"\"\"Load the specified file indices as an np array of shape (len(file_idxs), sr*duration)\"\"\"\n",
    "        if sr is None:\n",
    "            sr = self.sr\n",
    "        if duration is None:\n",
    "            duration = self.duration\n",
    "        ys = []\n",
    "        if pbar is not None:\n",
    "            pbar.reset(total=len(file_idxs))\n",
    "        for file_idx in file_idxs:\n",
    "            y, _ = librosa.load(self.files[file_idx], sr=sr, mono=True, offset=0.0, duration=duration)\n",
    "            y = librosa.util.fix_length(y, int(sr*duration), mode='wrap')\n",
    "            ys.append(y)\n",
    "            if pbar is not None:\n",
    "                pbar.update(1)\n",
    "        return np.array(ys)\n",
    "\n",
    "    def load_next(self, batch_size, sr=None, duration=None, pbar=None):\n",
    "        \"\"\"Load the next batch_size files as an np array of shape (batch_size, sr*duration)\"\"\"\n",
    "        if self.current_file_idx + batch_size > self.num_samples():\n",
    "            self.current_file_idx = 0\n",
    "            \n",
    "        file_idxs = range(self.current_file_idx, self.current_file_idx + batch_size)\n",
    "        self.current_file_idx += batch_size\n",
    "        return self.load(file_idxs, sr=sr, duration=duration, pbar=pbar)\n",
    "    def reset_next(self):\n",
    "        \"\"\"Reset the file index for the load_next function.\"\"\"\n",
    "        self.current_file_idx = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reformatting datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = 8000\n",
    "duration = 5.0\n",
    "voice_ds = AudioDataSet('datasets/LibriSpeech/LibriSpeech/dev-clean', sr=sr, duration=duration)\n",
    "noise_ds = AudioDataSet('datasets/urban/UrbanSound8K/audio', sr=sr, duration=duration)\n",
    "\n",
    "num_samples = voice_ds.num_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voice = voice_ds.load(range(num_samples), pbar=tqdm())\n",
    "print(voice.shape)\n",
    "np.save('datasets/voices', voice)\n",
    "del voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = noise_ds.load(range(num_samples), pbar=tqdm())\n",
    "print(noise.shape)\n",
    "np.save('datasets/noises', noise)\n",
    "del noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Fast Load Speeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "voice = np.load('datasets/voices.npy')\n",
    "noise = np.load('datasets/noises.npy')\n",
    "print(voice.shape)\n",
    "print(noise.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import librosa\n",
    "\n",
    "import torchaudio\n",
    "import torch\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sr = 8000\n",
    "duration = 2.0\n",
    "\n",
    "audio_endings = ('.mp3', '.wav', '.flac')\n",
    "files = []\n",
    "\n",
    "\n",
    "for r, d, f in os.walk('datasets/UrbanSound8K/UrbanSound8K/audio'):\n",
    "    for file in f:\n",
    "        if file.endswith(audio_endings) and file.split('-')[1]=='0':\n",
    "            files.append(os.path.join(r, file))\n",
    "\n",
    "ys = []\n",
    "for file in tqdm(files):\n",
    "    y, _ = librosa.load(file, sr=sr, mono=True, offset=0.0, duration=duration)\n",
    "    y = librosa.util.fix_length(y, int(sr*duration), mode='wrap')\n",
    "    ys.append(y)\n",
    "    \n",
    "ys = torch.from_numpy(np.array(ys))\n",
    "np.save(f'datasets/air_conditioning_sr{sr}_dur{duration}', ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42dd6de46a2f435bbfb5ead3bb45e0b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akarshkumar0101/.local/lib/python3.7/site-packages/librosa/core/audio.py:161: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sr = 8000\n",
    "duration = 2.0\n",
    "\n",
    "audio_endings = ('.mp3', '.wav', '.flac')\n",
    "files = []\n",
    "\n",
    "\n",
    "for r, d, f in os.walk('datasets/LibriSpeech/LibriSpeech/train-clean-100/'):\n",
    "    for file in f:\n",
    "        if file.endswith(audio_endings):\n",
    "            files.append(os.path.join(r, file))\n",
    "            \n",
    "files = files[:15000]\n",
    "print(len(files))\n",
    "            \n",
    "ys = []\n",
    "for file in tqdm(files):\n",
    "    y, _ = librosa.load(file, sr=sr, mono=True, offset=0.0, duration=duration)\n",
    "    y = librosa.util.fix_length(y, int(sr*duration), mode='wrap')\n",
    "    ys.append(y)\n",
    "    \n",
    "ys = torch.from_numpy(np.array(ys))\n",
    "np.save(f'datasets/voices_sr{sr}_dur{duration}', ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = np.load('datasets/air_conditioning_sr8000_dur2.0.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_ds = np.concatenate([ds for _ in range(15)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f'datasets/air_conditioning_sr{sr}_dur{duration}_num{full_ds.shape[0]}', full_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
